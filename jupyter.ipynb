{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan_ID</th>\n      <th>Gender</th>\n      <th>Married</th>\n      <th>Dependents</th>\n      <th>Education</th>\n      <th>Self_Employed</th>\n      <th>ApplicantIncome</th>\n      <th>CoapplicantIncome</th>\n      <th>LoanAmount</th>\n      <th>Loan_Amount_Term</th>\n      <th>Credit_History</th>\n      <th>Property_Area</th>\n      <th>Loan_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LP001002</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>5849</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LP001003</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4583</td>\n      <td>1508.0</td>\n      <td>128.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LP001005</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>3000</td>\n      <td>0.0</td>\n      <td>66.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LP001006</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>2583</td>\n      <td>2358.0</td>\n      <td>120.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LP001008</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>6000</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LP001011</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>5417</td>\n      <td>4196.0</td>\n      <td>267.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LP001013</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>2333</td>\n      <td>1516.0</td>\n      <td>95.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LP001014</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>3+</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3036</td>\n      <td>2504.0</td>\n      <td>158.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>LP001018</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4006</td>\n      <td>1526.0</td>\n      <td>168.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LP001020</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>12841</td>\n      <td>10968.0</td>\n      <td>349.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LP001024</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3200</td>\n      <td>700.0</td>\n      <td>70.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>LP001027</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>NaN</td>\n      <td>2500</td>\n      <td>1840.0</td>\n      <td>109.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>LP001028</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3073</td>\n      <td>8106.0</td>\n      <td>200.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>LP001029</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>1853</td>\n      <td>2840.0</td>\n      <td>114.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LP001030</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>1299</td>\n      <td>1086.0</td>\n      <td>17.0</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>LP001032</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4950</td>\n      <td>0.0</td>\n      <td>125.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>LP001034</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>1</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>3596</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>240.0</td>\n      <td>NaN</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>LP001036</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3510</td>\n      <td>0.0</td>\n      <td>76.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Urban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>LP001038</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>4887</td>\n      <td>0.0</td>\n      <td>133.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>LP001041</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>NaN</td>\n      <td>2600</td>\n      <td>3500.0</td>\n      <td>115.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>LP001043</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>7660</td>\n      <td>0.0</td>\n      <td>104.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Urban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>LP001046</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>5955</td>\n      <td>5625.0</td>\n      <td>315.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>LP001047</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>2600</td>\n      <td>1911.0</td>\n      <td>116.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>LP001050</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>3365</td>\n      <td>1917.0</td>\n      <td>112.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>LP001052</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>NaN</td>\n      <td>3717</td>\n      <td>2925.0</td>\n      <td>151.0</td>\n      <td>360.0</td>\n      <td>NaN</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>LP001066</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>9560</td>\n      <td>0.0</td>\n      <td>191.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LP001068</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>2799</td>\n      <td>2253.0</td>\n      <td>122.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>LP001073</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>4226</td>\n      <td>1040.0</td>\n      <td>110.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>LP001086</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>1442</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>LP001087</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>NaN</td>\n      <td>3750</td>\n      <td>2083.0</td>\n      <td>120.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>584</th>\n      <td>LP002911</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>2787</td>\n      <td>1917.0</td>\n      <td>146.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>585</th>\n      <td>LP002912</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4283</td>\n      <td>3000.0</td>\n      <td>172.0</td>\n      <td>84.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>586</th>\n      <td>LP002916</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>2297</td>\n      <td>1522.0</td>\n      <td>104.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>587</th>\n      <td>LP002917</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>2165</td>\n      <td>0.0</td>\n      <td>70.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>LP002925</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4750</td>\n      <td>0.0</td>\n      <td>94.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>LP002926</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>2726</td>\n      <td>0.0</td>\n      <td>106.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>590</th>\n      <td>LP002928</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3000</td>\n      <td>3416.0</td>\n      <td>56.0</td>\n      <td>180.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>LP002931</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>6000</td>\n      <td>0.0</td>\n      <td>205.0</td>\n      <td>240.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>LP002933</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>3+</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>9357</td>\n      <td>0.0</td>\n      <td>292.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>LP002936</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3859</td>\n      <td>3300.0</td>\n      <td>142.0</td>\n      <td>180.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>LP002938</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>16120</td>\n      <td>0.0</td>\n      <td>260.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>LP002940</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>3833</td>\n      <td>0.0</td>\n      <td>110.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>LP002941</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Not Graduate</td>\n      <td>Yes</td>\n      <td>6383</td>\n      <td>1000.0</td>\n      <td>187.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>LP002943</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>2987</td>\n      <td>0.0</td>\n      <td>88.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>598</th>\n      <td>LP002945</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>9963</td>\n      <td>0.0</td>\n      <td>180.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>599</th>\n      <td>LP002948</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>5780</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <td>LP002949</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>3+</td>\n      <td>Graduate</td>\n      <td>NaN</td>\n      <td>416</td>\n      <td>41667.0</td>\n      <td>350.0</td>\n      <td>180.0</td>\n      <td>NaN</td>\n      <td>Urban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>601</th>\n      <td>LP002950</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>NaN</td>\n      <td>2894</td>\n      <td>2792.0</td>\n      <td>155.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>602</th>\n      <td>LP002953</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>3+</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>5703</td>\n      <td>0.0</td>\n      <td>128.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>603</th>\n      <td>LP002958</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3676</td>\n      <td>4301.0</td>\n      <td>172.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>604</th>\n      <td>LP002959</td>\n      <td>Female</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>12000</td>\n      <td>0.0</td>\n      <td>496.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>605</th>\n      <td>LP002960</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>2400</td>\n      <td>3800.0</td>\n      <td>NaN</td>\n      <td>180.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>LP002961</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3400</td>\n      <td>2500.0</td>\n      <td>173.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Semiurban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>LP002964</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>3987</td>\n      <td>1411.0</td>\n      <td>157.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>LP002974</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>3232</td>\n      <td>1950.0</td>\n      <td>108.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>LP002978</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>2900</td>\n      <td>0.0</td>\n      <td>71.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>LP002979</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>3+</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4106</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>180.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>611</th>\n      <td>LP002983</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>8072</td>\n      <td>240.0</td>\n      <td>253.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>612</th>\n      <td>LP002984</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>7583</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>LP002990</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>4583</td>\n      <td>0.0</td>\n      <td>133.0</td>\n      <td>360.0</td>\n      <td>0.0</td>\n      <td>Semiurban</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>614 rows \u00d7 13 columns</p>\n</div>",
                        "text/plain": "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n0    LP001002    Male      No          0      Graduate            No   \n1    LP001003    Male     Yes          1      Graduate            No   \n2    LP001005    Male     Yes          0      Graduate           Yes   \n3    LP001006    Male     Yes          0  Not Graduate            No   \n4    LP001008    Male      No          0      Graduate            No   \n5    LP001011    Male     Yes          2      Graduate           Yes   \n6    LP001013    Male     Yes          0  Not Graduate            No   \n7    LP001014    Male     Yes         3+      Graduate            No   \n8    LP001018    Male     Yes          2      Graduate            No   \n9    LP001020    Male     Yes          1      Graduate            No   \n10   LP001024    Male     Yes          2      Graduate            No   \n11   LP001027    Male     Yes          2      Graduate           NaN   \n12   LP001028    Male     Yes          2      Graduate            No   \n13   LP001029    Male      No          0      Graduate            No   \n14   LP001030    Male     Yes          2      Graduate            No   \n15   LP001032    Male      No          0      Graduate            No   \n16   LP001034    Male      No          1  Not Graduate            No   \n17   LP001036  Female      No          0      Graduate            No   \n18   LP001038    Male     Yes          0  Not Graduate            No   \n19   LP001041    Male     Yes          0      Graduate           NaN   \n20   LP001043    Male     Yes          0  Not Graduate            No   \n21   LP001046    Male     Yes          1      Graduate            No   \n22   LP001047    Male     Yes          0  Not Graduate            No   \n23   LP001050     NaN     Yes          2  Not Graduate            No   \n24   LP001052    Male     Yes          1      Graduate           NaN   \n25   LP001066    Male     Yes          0      Graduate           Yes   \n26   LP001068    Male     Yes          0      Graduate            No   \n27   LP001073    Male     Yes          2  Not Graduate            No   \n28   LP001086    Male      No          0  Not Graduate            No   \n29   LP001087  Female      No          2      Graduate           NaN   \n..        ...     ...     ...        ...           ...           ...   \n584  LP002911    Male     Yes          1      Graduate            No   \n585  LP002912    Male     Yes          1      Graduate            No   \n586  LP002916    Male     Yes          0      Graduate            No   \n587  LP002917  Female      No          0  Not Graduate            No   \n588  LP002925     NaN      No          0      Graduate            No   \n589  LP002926    Male     Yes          2      Graduate           Yes   \n590  LP002928    Male     Yes          0      Graduate            No   \n591  LP002931    Male     Yes          2      Graduate           Yes   \n592  LP002933     NaN      No         3+      Graduate           Yes   \n593  LP002936    Male     Yes          0      Graduate            No   \n594  LP002938    Male     Yes          0      Graduate           Yes   \n595  LP002940    Male      No          0  Not Graduate            No   \n596  LP002941    Male     Yes          2  Not Graduate           Yes   \n597  LP002943    Male      No        NaN      Graduate            No   \n598  LP002945    Male     Yes          0      Graduate           Yes   \n599  LP002948    Male     Yes          2      Graduate            No   \n600  LP002949  Female      No         3+      Graduate           NaN   \n601  LP002950    Male     Yes          0  Not Graduate           NaN   \n602  LP002953    Male     Yes         3+      Graduate            No   \n603  LP002958    Male      No          0      Graduate            No   \n604  LP002959  Female     Yes          1      Graduate            No   \n605  LP002960    Male     Yes          0  Not Graduate            No   \n606  LP002961    Male     Yes          1      Graduate            No   \n607  LP002964    Male     Yes          2  Not Graduate            No   \n608  LP002974    Male     Yes          0      Graduate            No   \n609  LP002978  Female      No          0      Graduate            No   \n610  LP002979    Male     Yes         3+      Graduate            No   \n611  LP002983    Male     Yes          1      Graduate            No   \n612  LP002984    Male     Yes          2      Graduate            No   \n613  LP002990  Female      No          0      Graduate           Yes   \n\n     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n0               5849                0.0         NaN             360.0   \n1               4583             1508.0       128.0             360.0   \n2               3000                0.0        66.0             360.0   \n3               2583             2358.0       120.0             360.0   \n4               6000                0.0       141.0             360.0   \n5               5417             4196.0       267.0             360.0   \n6               2333             1516.0        95.0             360.0   \n7               3036             2504.0       158.0             360.0   \n8               4006             1526.0       168.0             360.0   \n9              12841            10968.0       349.0             360.0   \n10              3200              700.0        70.0             360.0   \n11              2500             1840.0       109.0             360.0   \n12              3073             8106.0       200.0             360.0   \n13              1853             2840.0       114.0             360.0   \n14              1299             1086.0        17.0             120.0   \n15              4950                0.0       125.0             360.0   \n16              3596                0.0       100.0             240.0   \n17              3510                0.0        76.0             360.0   \n18              4887                0.0       133.0             360.0   \n19              2600             3500.0       115.0               NaN   \n20              7660                0.0       104.0             360.0   \n21              5955             5625.0       315.0             360.0   \n22              2600             1911.0       116.0             360.0   \n23              3365             1917.0       112.0             360.0   \n24              3717             2925.0       151.0             360.0   \n25              9560                0.0       191.0             360.0   \n26              2799             2253.0       122.0             360.0   \n27              4226             1040.0       110.0             360.0   \n28              1442                0.0        35.0             360.0   \n29              3750             2083.0       120.0             360.0   \n..               ...                ...         ...               ...   \n584             2787             1917.0       146.0             360.0   \n585             4283             3000.0       172.0              84.0   \n586             2297             1522.0       104.0             360.0   \n587             2165                0.0        70.0             360.0   \n588             4750                0.0        94.0             360.0   \n589             2726                0.0       106.0             360.0   \n590             3000             3416.0        56.0             180.0   \n591             6000                0.0       205.0             240.0   \n592             9357                0.0       292.0             360.0   \n593             3859             3300.0       142.0             180.0   \n594            16120                0.0       260.0             360.0   \n595             3833                0.0       110.0             360.0   \n596             6383             1000.0       187.0             360.0   \n597             2987                0.0        88.0             360.0   \n598             9963                0.0       180.0             360.0   \n599             5780                0.0       192.0             360.0   \n600              416            41667.0       350.0             180.0   \n601             2894             2792.0       155.0             360.0   \n602             5703                0.0       128.0             360.0   \n603             3676             4301.0       172.0             360.0   \n604            12000                0.0       496.0             360.0   \n605             2400             3800.0         NaN             180.0   \n606             3400             2500.0       173.0             360.0   \n607             3987             1411.0       157.0             360.0   \n608             3232             1950.0       108.0             360.0   \n609             2900                0.0        71.0             360.0   \n610             4106                0.0        40.0             180.0   \n611             8072              240.0       253.0             360.0   \n612             7583                0.0       187.0             360.0   \n613             4583                0.0       133.0             360.0   \n\n     Credit_History Property_Area Loan_Status  \n0               1.0         Urban           Y  \n1               1.0         Rural           N  \n2               1.0         Urban           Y  \n3               1.0         Urban           Y  \n4               1.0         Urban           Y  \n5               1.0         Urban           Y  \n6               1.0         Urban           Y  \n7               0.0     Semiurban           N  \n8               1.0         Urban           Y  \n9               1.0     Semiurban           N  \n10              1.0         Urban           Y  \n11              1.0         Urban           Y  \n12              1.0         Urban           Y  \n13              1.0         Rural           N  \n14              1.0         Urban           Y  \n15              1.0         Urban           Y  \n16              NaN         Urban           Y  \n17              0.0         Urban           N  \n18              1.0         Rural           N  \n19              1.0         Urban           Y  \n20              0.0         Urban           N  \n21              1.0         Urban           Y  \n22              0.0     Semiurban           N  \n23              0.0         Rural           N  \n24              NaN     Semiurban           N  \n25              1.0     Semiurban           Y  \n26              1.0     Semiurban           Y  \n27              1.0         Urban           Y  \n28              1.0         Urban           N  \n29              1.0     Semiurban           Y  \n..              ...           ...         ...  \n584             0.0         Rural           N  \n585             1.0         Rural           N  \n586             1.0         Urban           Y  \n587             1.0     Semiurban           Y  \n588             1.0     Semiurban           Y  \n589             0.0     Semiurban           N  \n590             1.0     Semiurban           Y  \n591             1.0     Semiurban           N  \n592             1.0     Semiurban           Y  \n593             1.0         Rural           Y  \n594             1.0         Urban           Y  \n595             1.0         Rural           Y  \n596             1.0         Rural           N  \n597             0.0     Semiurban           N  \n598             1.0         Rural           Y  \n599             1.0         Urban           Y  \n600             NaN         Urban           N  \n601             1.0         Rural           Y  \n602             1.0         Urban           Y  \n603             1.0         Rural           Y  \n604             1.0     Semiurban           Y  \n605             1.0         Urban           N  \n606             1.0     Semiurban           Y  \n607             1.0         Rural           Y  \n608             1.0         Rural           Y  \n609             1.0         Rural           Y  \n610             1.0         Rural           Y  \n611             1.0         Urban           Y  \n612             1.0         Urban           Y  \n613             0.0     Semiurban           N  \n\n[614 rows x 13 columns]"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Male      489\nFemale    112\nName: Gender, dtype: int64"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Gender'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "df['Gender']=df.Gender.fillna('Male')"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Yes    398\nNo     213\nName: Married, dtype: int64"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Married'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "df['Married']=df.Married.fillna('Yes')"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0     345\n1     102\n2     101\n3+     51\nName: Dependents, dtype: int64"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Dependents'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "df['Dependents']=df.Dependents.fillna('0')"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "No     500\nYes     82\nName: Self_Employed, dtype: int64"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Self_Employed'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "df['Self_Employed']=df.Self_Employed.fillna('No')"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "df.LoanAmount = df.LoanAmount.fillna(df.LoanAmount.mean())"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "360.0    512\n180.0     44\n480.0     15\n300.0     13\n84.0       4\n240.0      4\n120.0      3\n36.0       2\n60.0       2\n12.0       1\nName: Loan_Amount_Term, dtype: int64"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Loan_Amount_Term'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "df.Loan_Amount_Term = df.Loan_Amount_Term.fillna(360.0)"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1.0    475\n0.0     89\nName: Credit_History, dtype: int64"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Credit_History'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "df.Credit_History = df.Credit_History.fillna(1.0)"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Loan_ID              False\nGender               False\nMarried              False\nDependents           False\nEducation            False\nSelf_Employed        False\nApplicantIncome      False\nCoapplicantIncome    False\nLoanAmount           False\nLoan_Amount_Term     False\nCredit_History       False\nProperty_Area        False\nLoan_Status          False\ndtype: bool"
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.isnull().any(axis=0)"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([['Male', 'No', '0', ..., 360.0, 1.0, 'Urban'],\n       ['Male', 'Yes', '1', ..., 360.0, 1.0, 'Rural'],\n       ['Male', 'Yes', '0', ..., 360.0, 1.0, 'Urban'],\n       ...,\n       ['Male', 'Yes', '1', ..., 360.0, 1.0, 'Urban'],\n       ['Male', 'Yes', '2', ..., 360.0, 1.0, 'Urban'],\n       ['Female', 'No', '0', ..., 360.0, 0.0, 'Semiurban']], dtype=object)"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "x=df.drop('Loan_Status',axis=1)\nx=x.drop('Loan_ID',axis=1).values\nx"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array(['Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'Y', 'N', 'N', 'N', 'Y',\n       'Y', 'Y', 'N', 'Y', 'N', 'N', 'N', 'Y', 'N', 'Y', 'N', 'Y', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'N', 'N', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'N',\n       'N', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'N',\n       'N', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'N', 'N', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'N', 'N', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N',\n       'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'N',\n       'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y',\n       'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'N', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'N',\n       'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y',\n       'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'N', 'N',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y',\n       'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N',\n       'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y',\n       'Y', 'N', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'N', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'N', 'N', 'N', 'Y', 'N', 'Y', 'N', 'Y',\n       'N', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'N', 'N', 'Y', 'N', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y',\n       'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'N', 'N', 'N',\n       'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N',\n       'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'N', 'Y', 'N',\n       'Y', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'N',\n       'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'N'], dtype=object)"
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y=df['Loan_Status'].values\ny"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(368, 11) (368,)\n(246, 11) (246,)\n"
                }
            ],
            "source": "from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.40)\nprint(x_train.shape,y_train.shape)\nprint(x_test.shape,y_test.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array(['Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'Y', 'N', 'N', 'N', 'Y',\n       'Y', 'Y', 'N', 'Y', 'N', 'N', 'N', 'Y', 'N', 'Y', 'N', 'Y', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'N', 'N', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'N',\n       'N', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'N',\n       'N', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'N', 'N', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'N', 'N', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N',\n       'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'N',\n       'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y',\n       'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'N', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'N',\n       'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y',\n       'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'N', 'N',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y',\n       'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N',\n       'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'N', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y',\n       'Y', 'N', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'N', 'Y',\n       'Y', 'N', 'Y', 'Y', 'Y', 'N', 'N', 'N', 'Y', 'N', 'Y', 'N', 'Y',\n       'N', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'N', 'N', 'Y', 'N', 'Y', 'Y',\n       'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y',\n       'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n       'N', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'N', 'N', 'N',\n       'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N',\n       'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y',\n       'N', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N', 'N', 'Y', 'N',\n       'Y', 'N', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'N',\n       'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N',\n       'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y',\n       'Y', 'Y', 'N'], dtype=object)"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y=df['Loan_Status'].values\ny"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": "\nfor i in range(0, 5):\n    x_train[:,i] = labelencoder_X.fit_transform(x_train[:,i])\n\nx_train[:,10] = labelencoder_X.fit_transform(x_train[:,10])"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": "labelencoder_y = LabelEncoder()\ny_train = labelencoder_y.fit_transform(y_train)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[1, 1, 0, ..., 360.0, 1.0, 2],\n       [1, 1, 0, ..., 360.0, 1.0, 0],\n       [1, 0, 2, ..., 360.0, 1.0, 1],\n       ...,\n       [0, 0, 0, ..., 360.0, 1.0, 0],\n       [0, 0, 1, ..., 360.0, 1.0, 1],\n       [1, 1, 2, ..., 180.0, 1.0, 1]], dtype=object)"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "x_train"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1])"
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y_train"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": "for i in range(0, 5):\n    x_test[:,i] = labelencoder_X.fit_transform(x_test[:,i])\nx_test[:,10] = labelencoder_X.fit_transform(x_test[:,10])\n\nlabelencoder_y = LabelEncoder()\ny_test = labelencoder_y.fit_transform(y_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[1, 1, 1, ..., 360.0, 1.0, 1],\n       [1, 1, 0, ..., 360.0, 1.0, 0],\n       [0, 0, 0, ..., 480.0, 1.0, 0],\n       ...,\n       [1, 1, 1, ..., 360.0, 1.0, 0],\n       [1, 1, 0, ..., 360.0, 0.0, 2],\n       [1, 1, 1, ..., 360.0, 0.0, 0]], dtype=object)"
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "x_test"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n       1, 0, 0, 0])"
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y_test"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.linear_model import LogisticRegression\nlog= LogisticRegression()\nlog.fit(x_train, y_train)\nlog.fit(x_test,y_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 0])"
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pred = log.predict(x_test)\npred"
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0.24206955, 0.75793045],\n       [0.21574237, 0.78425763],\n       [0.27679648, 0.72320352],\n       [0.2190625 , 0.7809375 ],\n       [0.88816674, 0.11183326],\n       [0.20153928, 0.79846072],\n       [0.19628678, 0.80371322],\n       [0.14897928, 0.85102072],\n       [0.22944531, 0.77055469],\n       [0.26100063, 0.73899937],\n       [0.21707672, 0.78292328],\n       [0.22337617, 0.77662383],\n       [0.303731  , 0.696269  ],\n       [0.24673177, 0.75326823],\n       [0.14705292, 0.85294708],\n       [0.30716695, 0.69283305],\n       [0.27930027, 0.72069973],\n       [0.26379056, 0.73620944],\n       [0.20029926, 0.79970074],\n       [0.71818421, 0.28181579],\n       [0.2612011 , 0.7387989 ],\n       [0.19439314, 0.80560686],\n       [0.80141366, 0.19858634],\n       [0.30980399, 0.69019601],\n       [0.2188469 , 0.7811531 ],\n       [0.30577895, 0.69422105],\n       [0.07588263, 0.92411737],\n       [0.2378054 , 0.7621946 ],\n       [0.29637294, 0.70362706],\n       [0.19881255, 0.80118745],\n       [0.21394828, 0.78605172],\n       [0.09004464, 0.90995536],\n       [0.8943851 , 0.1056149 ],\n       [0.18613324, 0.81386676],\n       [0.13366665, 0.86633335],\n       [0.17681277, 0.82318723],\n       [0.3052898 , 0.6947102 ],\n       [0.22229959, 0.77770041],\n       [0.08612805, 0.91387195],\n       [0.18592685, 0.81407315],\n       [0.60371834, 0.39628166],\n       [0.15175162, 0.84824838],\n       [0.83491913, 0.16508087],\n       [0.21995313, 0.78004687],\n       [0.24757715, 0.75242285],\n       [0.21285307, 0.78714693],\n       [0.21918867, 0.78081133],\n       [0.86622614, 0.13377386],\n       [0.20203714, 0.79796286],\n       [0.31026466, 0.68973534],\n       [0.2076069 , 0.7923931 ],\n       [0.18222927, 0.81777073],\n       [0.80614781, 0.19385219],\n       [0.22639689, 0.77360311],\n       [0.21646368, 0.78353632],\n       [0.26444437, 0.73555563],\n       [0.25434422, 0.74565578],\n       [0.90288429, 0.09711571],\n       [0.27731618, 0.72268382],\n       [0.88856018, 0.11143982],\n       [0.23139789, 0.76860211],\n       [0.29841821, 0.70158179],\n       [0.21665427, 0.78334573],\n       [0.29798442, 0.70201558],\n       [0.83460852, 0.16539148],\n       [0.10915634, 0.89084366],\n       [0.27030456, 0.72969544],\n       [0.15707394, 0.84292606],\n       [0.83347757, 0.16652243],\n       [0.29724284, 0.70275716],\n       [0.16752193, 0.83247807],\n       [0.21343206, 0.78656794],\n       [0.13318542, 0.86681458],\n       [0.85421571, 0.14578429],\n       [0.20302686, 0.79697314],\n       [0.86484165, 0.13515835],\n       [0.3738897 , 0.6261103 ],\n       [0.31453142, 0.68546858],\n       [0.28963151, 0.71036849],\n       [0.32186847, 0.67813153],\n       [0.87630197, 0.12369803],\n       [0.31468658, 0.68531342],\n       [0.3790118 , 0.6209882 ],\n       [0.3576345 , 0.6423655 ],\n       [0.27789557, 0.72210443],\n       [0.21006186, 0.78993814],\n       [0.3060898 , 0.6939102 ],\n       [0.28244875, 0.71755125],\n       [0.30194439, 0.69805561],\n       [0.23472953, 0.76527047],\n       [0.28630113, 0.71369887],\n       [0.35614624, 0.64385376],\n       [0.28180649, 0.71819351],\n       [0.11895981, 0.88104019],\n       [0.91452074, 0.08547926],\n       [0.34447277, 0.65552723],\n       [0.88791666, 0.11208334],\n       [0.12515814, 0.87484186],\n       [0.24948829, 0.75051171],\n       [0.27472403, 0.72527597],\n       [0.28134031, 0.71865969],\n       [0.3119791 , 0.6880209 ],\n       [0.18243628, 0.81756372],\n       [0.84470046, 0.15529954],\n       [0.30128303, 0.69871697],\n       [0.21937019, 0.78062981],\n       [0.12787867, 0.87212133],\n       [0.86297809, 0.13702191],\n       [0.26543581, 0.73456419],\n       [0.75620328, 0.24379672],\n       [0.26535816, 0.73464184],\n       [0.21544329, 0.78455671],\n       [0.2498829 , 0.7501171 ],\n       [0.31750951, 0.68249049],\n       [0.21536333, 0.78463667],\n       [0.18294028, 0.81705972],\n       [0.22320235, 0.77679765],\n       [0.20798397, 0.79201603],\n       [0.24043356, 0.75956644],\n       [0.28046585, 0.71953415],\n       [0.22202901, 0.77797099],\n       [0.32526994, 0.67473006],\n       [0.27077012, 0.72922988],\n       [0.31719361, 0.68280639],\n       [0.18639846, 0.81360154],\n       [0.19379285, 0.80620715],\n       [0.1323708 , 0.8676292 ],\n       [0.75691139, 0.24308861],\n       [0.22988694, 0.77011306],\n       [0.35833596, 0.64166404],\n       [0.13132716, 0.86867284],\n       [0.18914192, 0.81085808],\n       [0.21677923, 0.78322077],\n       [0.23174392, 0.76825608],\n       [0.29464539, 0.70535461],\n       [0.2296994 , 0.7703006 ],\n       [0.21678353, 0.78321647],\n       [0.23897481, 0.76102519],\n       [0.16919497, 0.83080503],\n       [0.24049357, 0.75950643],\n       [0.8021779 , 0.1978221 ],\n       [0.12363282, 0.87636718],\n       [0.20603031, 0.79396969],\n       [0.40247209, 0.59752791],\n       [0.17945874, 0.82054126],\n       [0.29246553, 0.70753447],\n       [0.2796641 , 0.7203359 ],\n       [0.26093621, 0.73906379],\n       [0.14872341, 0.85127659],\n       [0.28186988, 0.71813012],\n       [0.91025381, 0.08974619],\n       [0.18999197, 0.81000803],\n       [0.90186863, 0.09813137],\n       [0.25495901, 0.74504099],\n       [0.79535712, 0.20464288],\n       [0.24241945, 0.75758055],\n       [0.21480478, 0.78519522],\n       [0.20192339, 0.79807661],\n       [0.30545988, 0.69454012],\n       [0.2092233 , 0.7907767 ],\n       [0.25273378, 0.74726622],\n       [0.41647767, 0.58352233],\n       [0.21595149, 0.78404851],\n       [0.23601133, 0.76398867],\n       [0.09419786, 0.90580214],\n       [0.23861022, 0.76138978],\n       [0.31453506, 0.68546494],\n       [0.21708538, 0.78291462],\n       [0.22398703, 0.77601297],\n       [0.10710395, 0.89289605],\n       [0.25417044, 0.74582956],\n       [0.19459619, 0.80540381],\n       [0.22365689, 0.77634311],\n       [0.15851468, 0.84148532],\n       [0.72585696, 0.27414304],\n       [0.2479809 , 0.7520191 ],\n       [0.89320044, 0.10679956],\n       [0.71454637, 0.28545363],\n       [0.24609219, 0.75390781],\n       [0.86447623, 0.13552377],\n       [0.15787301, 0.84212699],\n       [0.21058394, 0.78941606],\n       [0.12424705, 0.87575295],\n       [0.32802376, 0.67197624],\n       [0.21658276, 0.78341724],\n       [0.09131583, 0.90868417],\n       [0.32618678, 0.67381322],\n       [0.890466  , 0.109534  ],\n       [0.27166642, 0.72833358],\n       [0.31365563, 0.68634437],\n       [0.29714699, 0.70285301],\n       [0.28140846, 0.71859154],\n       [0.20534628, 0.79465372],\n       [0.2575129 , 0.7424871 ],\n       [0.21508407, 0.78491593],\n       [0.88802871, 0.11197129],\n       [0.87260993, 0.12739007],\n       [0.8033442 , 0.1966558 ],\n       [0.87706538, 0.12293462],\n       [0.83963783, 0.16036217],\n       [0.79715675, 0.20284325],\n       [0.20215782, 0.79784218],\n       [0.82031861, 0.17968139],\n       [0.21169662, 0.78830338],\n       [0.82009272, 0.17990728],\n       [0.2001319 , 0.7998681 ],\n       [0.22529241, 0.77470759],\n       [0.27673092, 0.72326908],\n       [0.80078378, 0.19921622],\n       [0.28513343, 0.71486657],\n       [0.80686224, 0.19313776],\n       [0.30273721, 0.69726279],\n       [0.14673684, 0.85326316],\n       [0.30127999, 0.69872001],\n       [0.19080164, 0.80919836],\n       [0.19540436, 0.80459564],\n       [0.26683002, 0.73316998],\n       [0.28915755, 0.71084245],\n       [0.31064582, 0.68935418],\n       [0.18243834, 0.81756166],\n       [0.18316188, 0.81683812],\n       [0.29408277, 0.70591723],\n       [0.12614932, 0.87385068],\n       [0.17510218, 0.82489782],\n       [0.18481788, 0.81518212],\n       [0.27594528, 0.72405472],\n       [0.311396  , 0.688604  ],\n       [0.89035829, 0.10964171],\n       [0.12663764, 0.87336236],\n       [0.30134752, 0.69865248],\n       [0.33811444, 0.66188556],\n       [0.32111485, 0.67888515],\n       [0.85147549, 0.14852451],\n       [0.19999884, 0.80000116],\n       [0.9317827 , 0.0682173 ],\n       [0.13742764, 0.86257236],\n       [0.2328847 , 0.7671153 ],\n       [0.21313479, 0.78686521],\n       [0.25487303, 0.74512697],\n       [0.12723686, 0.87276314],\n       [0.85059334, 0.14940666],\n       [0.26697429, 0.73302571],\n       [0.20634411, 0.79365589],\n       [0.24018811, 0.75981189],\n       [0.85764655, 0.14235345],\n       [0.8484405 , 0.1515595 ]])"
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pred_prob=log.predict_proba(x_test)\npred_prob"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.8048780487804879"
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test,pred)"
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.4748488984255984"
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.metrics import log_loss\nlog_loss(y_test,pred_prob)"
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[ 42  44]\n [  4 156]]\n"
                }
            ],
            "source": "from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,pred)\nprint(cm)"
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.tree import DecisionTreeClassifier"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "drugTree=DecisionTreeClassifier(criterion='entropy')\ndrugTree"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "drugTree.fit(x_train,y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 1])"
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "predTree=drugTree.predict(x_test)\npredTree"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": "pred_prob2=drugTree.predict_proba(x_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "DecisionTree accuracy: 0.6788617886178862\n"
                }
            ],
            "source": "from sklearn import metrics\nprint('DecisionTree accuracy:',metrics.accuracy_score(y_test,predTree))"
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.8048780487804879"
                    },
                    "execution_count": 43,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "jaccard_similarity_score(y_test,pred)"
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.4748488984255984"
                    },
                    "execution_count": 44,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "log_loss(y_test,pred_prob)"
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[ 42  44]\n [  4 156]]\n"
                }
            ],
            "source": "cm = confusion_matrix(y_test,pred)\nprint(cm)"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.neighbors import KNeighborsClassifier"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n           weights='uniform')"
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "k=4\nK=KNeighborsClassifier()\nneigh=K.fit(x_train,y_train)\nneigh"
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": "pred1=K.predict(x_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": "pred_prob1=K.predict_proba(x_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "accuracy 0.8048780487804879\n"
                }
            ],
            "source": "print(\"accuracy\",metrics.accuracy_score(y_test,pred))"
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.8048780487804879"
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "jaccard_similarity_score(y_test,pred)"
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.4748488984255984"
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "log_loss(y_test,pred_prob)"
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[ 42  44]\n [  4 156]]\n"
                }
            ],
            "source": "cm = confusion_matrix(y_test,pred)\nprint(cm)"
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n  kernel='linear', max_iter=-1, probability=False, random_state=0,\n  shrinking=True, tol=0.001, verbose=False)"
                    },
                    "execution_count": 54,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(x_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The accuracy of SVM is:  0.7845528455284553\n"
                }
            ],
            "source": "y_pred = classifier.predict(x_test)\nfrom sklearn import metrics\nprint('The accuracy of SVM is: ', metrics.accuracy_score(y_pred, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.7845528455284553"
                    },
                    "execution_count": 56,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "jaccard_similarity_score(y_test,y_pred)"
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[ 39  47]\n [  6 154]]\n"
                }
            ],
            "source": "cm = confusion_matrix(y_test,y_pred)\nprint(cm)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}